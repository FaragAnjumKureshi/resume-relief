{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9ecf3e75dd0c1cbf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T16:27:15.452583Z",
          "start_time": "2025-03-24T16:27:14.793206Z"
        },
        "id": "9ecf3e75dd0c1cbf"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7518bc1498a63e48",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T16:27:15.735282Z",
          "start_time": "2025-03-24T16:27:15.731384Z"
        },
        "id": "7518bc1498a63e48"
      },
      "outputs": [],
      "source": [
        "DOMAIN = 'https://www.cake.me'\n",
        "FILTER_TAIWAN = '/jobs?location_list%5B0%5D=Taiwan'\n",
        "FILTER_SENIORITY = '&seniority_level%5B0%5D='\n",
        "FILTER_LATEST = '&order=latest'\n",
        "PAGING = '&page='\n",
        "LANG_ARTICLE = '?locale=en'\n",
        "SLEEP = 1\n",
        "NUMPAGE = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43c8c77d517bc738",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T16:27:15.464615Z",
          "start_time": "2025-03-24T16:27:15.457095Z"
        },
        "id": "43c8c77d517bc738"
      },
      "outputs": [],
      "source": [
        "seniority_list = [\n",
        "\t'internship_level',\n",
        "\t# 'entry_level',\n",
        "\t# 'mid_senior_level',\n",
        "\t# 'associate',\n",
        "\t'director',\n",
        "\t'executive',\n",
        "]\n",
        "\n",
        "job_metadata = {\n",
        "\t'title': 'title',\n",
        "\t'company_name': 'company_name',\n",
        "\t'company_field': 'company_field',\n",
        "\t'category_major': 'category_major',\n",
        "\t'category_minor': 'category_minor',\n",
        "\t'employment_type': 'employment_type',\n",
        "\t'seniority': 'seniority',\n",
        "\t'location': 'location',\n",
        "\t'number_of_hire': 'number_of_hire',\n",
        "\t'experience': 'experience',\n",
        "\t'salary_range': 'salary_range',\n",
        "\t'skills': 'skills',\n",
        "\t'job_description': 'job_description',\n",
        "\t'requirements': 'requirements',\n",
        "\t'job_url': 'job_url',\n",
        "\t'company_size': 'company_size',\n",
        "\t'company_address': 'company_address',\n",
        "\t'company_about': 'company_about',\n",
        "}\n",
        "\n",
        "job_columns = []\n",
        "for key, _ in job_metadata.items():\n",
        "\tjob_columns.append(key)\n",
        "\n",
        "jobs_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a0c6c6587eb62c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T16:27:15.761752Z",
          "start_time": "2025-03-24T16:27:15.744932Z"
        },
        "id": "c1a0c6c6587eb62c"
      },
      "outputs": [],
      "source": [
        "def getCakeresume(metadata, df, numPage=1):\n",
        "\tparseAllPagination(metadata, df, numPage)\n",
        "\treturn None\n",
        "\t\n",
        "def parseAllPagination(metadata, df, numPage):\n",
        "\tfor seniority in seniority_list:\n",
        "\t\tprint(f\"Processing seniority level: {seniority}\")\n",
        "\t\tseniority_df = pd.DataFrame(columns=df.columns)\n",
        "\t\t\n",
        "\t\tconsecutive_errors = 0\n",
        "\t\tmax_consecutive_errors = 3\n",
        "\t\t\n",
        "\t\tfor i in range(1, numPage + 1):\n",
        "\t\t\turl = DOMAIN + FILTER_TAIWAN + FILTER_SENIORITY + seniority + FILTER_LATEST + PAGING + str(i)\n",
        "\t\t\tprint(f\"Fetching page {i}/{numPage}: {url}\")\n",
        "\t\t\t\n",
        "\t\t\ttry:\n",
        "\t\t\t\tresult_df = parseList(url, metadata, seniority_df)\n",
        "\t\t\t\t\n",
        "\t\t\t\tif result_df is None: # Page error (like 404)\n",
        "\t\t\t\t\tconsecutive_errors += 1\n",
        "\t\t\t\t\tprint(f\"Error on page {i} - consecutive errors: {consecutive_errors}/{max_consecutive_errors}\")\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif consecutive_errors >= max_consecutive_errors:\n",
        "\t\t\t\t\t\tprint(f\"Reached {max_consecutive_errors} consecutive errors. Moving to next seniority level.\")\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\telse: # Successful page - reset error counter\n",
        "\t\t\t\t\tconsecutive_errors = 0\n",
        "\t\t\t\t\tseniority_df = result_df\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(f\"Exception on page {i}: {str(e)}\")\n",
        "\t\t\t\tconsecutive_errors += 1\n",
        "\t\t\t\t\n",
        "\t\t\t\tif consecutive_errors >= max_consecutive_errors:\n",
        "\t\t\t\t\tprint(f\"Reached {max_consecutive_errors} consecutive errors. Moving to next seniority level.\")\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\t\n",
        "\t\t\ttime.sleep(SLEEP)\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tseniority_df.to_csv(f'Jobs_{str(seniority)}.csv', index=False, encoding='utf-8-sig')\n",
        "\t\t\tprint(f\"Successfully saved {len(seniority_df)} jobs for '{seniority}'\")\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(f\"Error saving CSV for '{seniority}': {str(e)}\")\n",
        "\t\n",
        "\treturn None\n",
        "\n",
        "def parseList(url, metadata, df):\n",
        "\ttry:\n",
        "\t\tresp = requests.get(url, timeout=30)\n",
        "\t\t\n",
        "\t\tif resp.status_code != 200:\n",
        "\t\t\tprint(f\"HTTP Error {resp.status_code} for URL: {url}\")\n",
        "\t\t\treturn None\n",
        "\t\t\t\n",
        "\t\tdoc = BeautifulSoup(resp.text, \"lxml\")\n",
        "\t\tarticles = doc.find_all('a', class_='JobSearchItem_jobTitle__bu6yO')\n",
        "\t\t\n",
        "\t\tif not articles:\n",
        "\t\t\tprint(f\"No job listings found on page {url}\")\n",
        "\t\t\treturn df\n",
        "\t\t\t\n",
        "\t\tjobs_added = 0\n",
        "\t\t\n",
        "\t\tfor article in articles:\n",
        "\t\t\ttry:\n",
        "\t\t\t\tarticle_url = DOMAIN + article['href'] + LANG_ARTICLE\n",
        "\t\t\t\tarticle_metadata = metadata.copy()\n",
        "\t\t\t\tresult_df = parseArticle(article_url, article_metadata, df)\n",
        "\t\t\t\t\n",
        "\t\t\t\tif result_df is not None:\n",
        "\t\t\t\t\tdf = result_df\n",
        "\t\t\t\t\tjobs_added += 1\n",
        "\t\t\t\t\n",
        "\t\t\t\ttime.sleep(SLEEP)\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(f\"Error processing article {article.get('href', 'unknown')}: {str(e)}\")\n",
        "\t\t\t\t# Continue with next article\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t\t\n",
        "\t\tprint(f\"Added {jobs_added} jobs from page {url}\")\n",
        "\t\treturn df\n",
        "\t\t\n",
        "\texcept requests.RequestException as e:\n",
        "\t\tprint(f\"Request error for {url}: {str(e)}\")\n",
        "\t\treturn None \n",
        "\texcept Exception as e:\n",
        "\t\tprint(f\"Unexpected error processing page {url}: {str(e)}\")\n",
        "\t\treturn None\n",
        "\n",
        "def parseArticle(url, metadata, df):\n",
        "\ttry:\n",
        "\t\tresp = requests.get(url, timeout=30)\n",
        "\t\t\n",
        "\t\tif resp.status_code != 200:\n",
        "\t\t\tprint(f\"HTTP Error {resp.status_code} for article URL: {url}\")\n",
        "\t\t\treturn df\n",
        "\t\t\t\n",
        "\t\tdoc = BeautifulSoup(resp.text, \"lxml\")\n",
        "\t\t\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['title'] = doc.find('h1').text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['title'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['category_major'] = doc.find_all('span', class_='Breadcrumbs_labelText__ZXeZH')[3].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['category_major'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['category_minor'] = doc.find_all('span', class_='Breadcrumbs_labelText__ZXeZH')[4].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['category_minor'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['employment_type'] = doc.find_all('div', class_='JobDescriptionRightColumn_row__5rklX')[0].find_all('a')[0].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['employment_type'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['seniority'] = doc.find_all('div', class_='JobDescriptionRightColumn_row__5rklX')[0].find_all('a')[1].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['seniority'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['location'] = doc.find_all('div', class_='JobDescriptionRightColumn_row__5rklX')[1].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['location'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['number_of_hire'] = doc.find_all('div', class_='JobDescriptionRightColumn_row__5rklX')[2].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['number_of_hire'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['experience'] = doc.find_all('div', class_='JobDescriptionRightColumn_row__5rklX')[3].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['experience'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['salary_range'] = doc.find_all('div', class_='JobDescriptionRightColumn_row__5rklX')[4].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['salary_range'] = ''\n",
        "\n",
        "\t\t# Skills\n",
        "\t\ttry:\n",
        "\t\t\tskills_cloud = doc.find('div', class_='Tags_wrapper__UQ34T Tags_primary__yUsz1 Tags_tagsMedium__PC_Iu').find_all('a')\n",
        "\t\t\tskills = []\n",
        "\t\t\tfor skill in skills_cloud:\n",
        "\t\t\t\tskill = skill.text.strip()\n",
        "\t\t\t\tskills.append(skill)\n",
        "\t\t\tmetadata['skills'] = skills\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['skills'] = []\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['job_description'] = doc.find_all('div', class_='ContentSection_contentSection__ELRlG')[0].find('div', class_='RailsHtml_container__LlMcK').text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['job_description'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['requirements'] = doc.find_all('div', class_='ContentSection_contentSection__ELRlG')[1].find('div', class_='RailsHtml_container__LlMcK').text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['requirements'] = ''\n",
        "\n",
        "\t\tmetadata['job_url'] = url\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['company_name'] = doc.find('a', class_='AboutBlock_companyName__4YTC8').text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['company_name'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['company_url'] = DOMAIN + doc.find('a', class_='AboutBlock_companyName__4YTC8')['href']\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['company_url'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['company_field'] = doc.find_all('div', class_='CompanyInfoItem_container__jjp_r')[0].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['company_field'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['company_size'] = doc.find_all('div', class_='CompanyInfoItem_container__jjp_r')[1].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['company_size'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['company_address'] = doc.find_all('div', class_='CompanyInfoItem_container__jjp_r')[2].text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['company_address'] = ''\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\tmetadata['company_about'] = doc.find('div', class_='AboutBlock_companySummary__l6for').find('div', class_='RailsHtml_container__LlMcK').text.strip()\n",
        "\t\texcept (IndexError, AttributeError, TypeError):\n",
        "\t\t\tmetadata['company_about'] = ''\n",
        "\n",
        "\t\tmetadata_df = pd.DataFrame([metadata])\n",
        "\t\tupdated_df = pd.concat([df, metadata_df], ignore_index=True)\n",
        "\t\treturn updated_df\n",
        "\t\t\n",
        "\texcept requests.RequestException as e:\n",
        "\t\tprint(f\"Request error for article {url}: {str(e)}\")\n",
        "\t\treturn df\n",
        "\texcept Exception as e:\n",
        "\t\tprint(f\"Error processing article {url}: {str(e)}\")\n",
        "\t\treturn df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d33a97b3c1d3884",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-24T16:28:52.192610Z",
          "start_time": "2025-03-24T16:27:15.768870Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d33a97b3c1d3884",
        "outputId": "e6e41522-7bf4-4680-aa46-9490d9524357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://www.cake.me/jobs?location_list%5B0%5D=Taiwan&seniority_level%5B0%5D=internship_level&order=latest&page=90\n",
            "https://www.cake.me/jobs?location_list%5B0%5D=Taiwan&seniority_level%5B0%5D=internship_level&order=latest&page=91\n",
            "https://www.cake.me/jobs?location_list%5B0%5D=Taiwan&seniority_level%5B0%5D=internship_level&order=latest&page=92\n",
            "https://www.cake.me/jobs?location_list%5B0%5D=Taiwan&seniority_level%5B0%5D=internship_level&order=latest&page=93\n",
            "https://www.cake.me/jobs?location_list%5B0%5D=Taiwan&seniority_level%5B0%5D=internship_level&order=latest&page=94\n",
            "https://www.cake.me/jobs?location_list%5B0%5D=Taiwan&seniority_level%5B0%5D=internship_level&order=latest&page=95\n",
            "'NoneType' object has no attribute 'to_csv'\n",
            "https://www.cake.me/jobs?location_list%5B0%5D=Taiwan&seniority_level%5B0%5D=entry_level&order=latest&page=90\n",
            "https://www.cake.me/jobs?location_list%5B0%5D=Taiwan&seniority_level%5B0%5D=entry_level&order=latest&page=91\n",
            "https://www.cake.me/jobs?location_list%5B0%5D=Taiwan&seniority_level%5B0%5D=entry_level&order=latest&page=92\n",
            "https://www.cake.me/jobs?location_list%5B0%5D=Taiwan&seniority_level%5B0%5D=entry_level&order=latest&page=93\n"
          ]
        }
      ],
      "source": [
        "getCakeresume(metadata=job_metadata, df=jobs_df, numPage=NUMPAGE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "main",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
